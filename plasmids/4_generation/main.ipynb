{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "model_dir = '/Users/anastasiiashcherbakova/git_projects/masters_project/plasmids/2_models'\n",
    "sys.path.append(model_dir)\n",
    "\n",
    "from GANs_model_1 import *\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 6000\n",
    "vocab_size = 4\n",
    "num_epochs = 100\n",
    "noise_dim = 100\n",
    "input_size = max_length * vocab_size\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "generator = Generator(noise_dim, max_length, vocab_size).to(device)\n",
    "critic = Critic(input_size).to(device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of critic before loading state dict: <class 'GANs_model_1.Critic'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Type of critic before loading state dict: {type(critic)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.load_state_dict(torch.load('/Users/anastasiiashcherbakova/Desktop/GANs_model_1_output/saved_base_generator_mod.pt', map_location=torch.device('cpu')))\n",
    "critic.load_state_dict(torch.load('/Users/anastasiiashcherbakova/Desktop/GANs_model_1_output/saved_base_critic_mod.pt', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Critic(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=24000, out_features=128, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2)\n",
       "    (5): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (6): LeakyReLU(negative_slope=0.2)\n",
       "    (7): Dropout(p=0.3, inplace=False)\n",
       "    (8): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.eval()\n",
    "critic.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_linear_layer = generator.model[0]\n",
    "\n",
    "latent_dim = first_linear_layer.weight.shape[1]\n",
    "num_samples = 10\n",
    "\n",
    "random_latent_vectors = torch.randn(num_samples, latent_dim)\n",
    "\n",
    "with torch.no_grad():\n",
    "    generated_data = generator(random_latent_vectors)\n",
    "\n",
    "generated_data = generated_data.cpu().numpy()\n",
    "\n",
    "# for i, sequence in enumerate(generated_data):\n",
    "#     print(f\"Sequence {i+1}: {sequence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 6000, 4)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data_tensor = torch.tensor(generated_data, dtype=torch.float32).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 6000, 4])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_data_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data_tensor = generated_data_tensor.view(generated_data_tensor.size(0), -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 24000])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_data_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.load('/Users/anastasiiashcherbakova/Desktop/cleaned_sequences.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_tokenizer = Base_Level_Tokenizer()\n",
    "base_vocab = base_tokenizer.fit_on_texts(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "base_sequence_encoded = base_tokenizer.sequence_to_indices(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dataset = Dataset_Prep(base_sequence_encoded, max_length)\n",
    "base_dataloader = DataLoader(base_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_batch = next(iter(base_dataloader)) \n",
    "real_data_batch = real_data_batch.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 2,  ..., 0, 0, 0],\n",
       "        [0, 3, 3,  ..., 0, 1, 1],\n",
       "        [2, 2, 2,  ..., 2, 1, 2],\n",
       "        [1, 0, 0,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_actual = real_data_batch.size(0)\n",
    "real_data_one_hot = one_hot_encode_sequences(real_data_batch, vocab_size)\n",
    "real_data_one_hot = real_data_one_hot.view(batch_size_actual, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 1., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 24000])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Critic Score for Real Data: 1.394045114517212\n",
      "Mean Critic Score for Generated Data: 1.1481131315231323\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    real_scores = critic(real_data_one_hot)\n",
    "    generated_scores = critic(generated_data_tensor)\n",
    "\n",
    "# Compare the scores\n",
    "real_scores_mean = real_scores.mean().item()\n",
    "generated_scores_mean = generated_scores.mean().item()\n",
    "\n",
    "print(f\"Mean Critic Score for Real Data: {real_scores_mean}\")\n",
    "print(f\"Mean Critic Score for Generated Data: {generated_scores_mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
