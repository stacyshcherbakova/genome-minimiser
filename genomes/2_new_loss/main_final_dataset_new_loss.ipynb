{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from directories import *\n",
    "from VAE_models.VAE_model import *\n",
    "from VAE_models.VAE_model_enhanced import *\n",
    "from VAE_models.VAE_model_2 import *\n",
    "from VAE_models.VAE_model_single import *\n",
    "from training import *\n",
    "from extras import *\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import defaultdict\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Current working directory: {current_dir}\")\n",
    "print(f\"Parent directory: {parent_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data_exploration'></a>\n",
    "# 1) Data loading "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading essential genes and the dataset files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_genes = pd.read_csv(PAPER_ESSENTIAL_GENES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_data = pd.read_csv(TEN_K_DATASET, index_col=[0], header=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning all sample names uppercase for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_data.columns = large_data.columns.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_data.sum(axis=1).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the phylogroup metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_lineage = large_data.drop(index=['Lineage'])\n",
    "large_data_t = np.array(data_without_lineage.transpose())\n",
    "\n",
    "print(f\"Full dataset shape: {large_data_t.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) Dataset preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phylogroup_data = pd.read_csv(TEN_K_DATASET_PHYLOGROUPS, index_col=[0], header=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(data_without_lineage.transpose(), phylogroup_data, how='inner', left_index=True, right_on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array_t = np.array(merged_df.iloc[:, :-1])\n",
    "phylogroups_array = np.array(merged_df.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Checking dataset shapes\")\n",
    "print(f\"Values array: {data_array_t.shape}\")\n",
    "print(f\"Phylogroups array: {phylogroups_array.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) Conversing the dataset into splits and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensor\n",
    "data_tensor = torch.tensor(data_array_t, dtype=torch.float32)\n",
    "\n",
    "# Split into train and test sets\n",
    "train_data, temp_data, train_labels, temp_labels = train_test_split(data_tensor, phylogroups_array, test_size=0.3, random_state=12345)\n",
    "val_data, test_data, val_labels, test_labels = train_test_split(temp_data, temp_labels, test_size=0.3333, random_state=12345)\n",
    "test_phylogroups = test_labels\n",
    "\n",
    "# Set batch size\n",
    "batch_size = 32\n",
    "\n",
    "# TensorDataset\n",
    "train_dataset = TensorDataset(train_data)\n",
    "val_dataset = TensorDataset(val_data)\n",
    "test_dataset = TensorDataset(test_data)\n",
    "\n",
    "# Set laoders\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train data shape {train_data.shape}\")\n",
    "print(f\"Test data shape {test_data.shape}\")\n",
    "print(f\"Val data shape {val_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Essential genes manipulatioins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an array of essential genes fromt the paper and flattening it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_genes_array = np.array(essential_genes).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of essential genes present in the paper: {len(essential_genes_array)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a gene mask for the essential arrays for more optimal counting of the essential arrays present in the samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genes = merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_genes_mask = np.isin(all_genes, essential_genes_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of essential genes present in the dataset: {np.sum(essential_genes_mask)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figuring out which genes are not present in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_not_in_essential_genes_mask = essential_genes[~np.isin(np.array(essential_genes), np.array(all_genes[essential_genes_mask]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figuring out which genes are present in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_in_essential_genes_mask = essential_genes[np.isin(np.array(essential_genes), np.array(all_genes[essential_genes_mask]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absent_genes = np.array(subset_not_in_essential_genes_mask).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of genes not present in the dataset: {len(absent_genes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "present_genes = np.array(subset_in_essential_genes_mask).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of genes present in the dataset: {len(present_genes)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing if the genes split into multiple parts in the dataset are the essential genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_columns = []\n",
    "\n",
    "for gene in absent_genes:\n",
    "    pattern = re.compile(f\"{gene}\")\n",
    "    matches = [col for col in merged_df.columns if pattern.match(col) and col not in present_genes]\n",
    "    matched_columns.extend(matches)\n",
    "\n",
    "\n",
    "divided_genes = np.array(matched_columns)\n",
    "print(divided_genes)\n",
    "print(len(divided_genes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually creating the array of genes which is divided into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divided_genes_prefixes = ['msbA', 'fabG', 'lolD', 'topA', 'metG', 'fbaA', 'higA', 'lptB', 'ssb',  'lptG', 'dnaC'] # 'higA-1', 'higA1','higA-2', 'ssbA' dont count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_present = np.array(list(set(absent_genes) - set(divided_genes_prefixes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Genes which are still not present in the dataset after prefix extraction: {not_present}\")\n",
    "print(f\"Total number: {len(not_present)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a new array of the genes (both sigle name and didived) present in the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_array = np.concatenate((present_genes, divided_genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total umber of genes that count as essential in the dataset: {len(combined_array)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a new gene mask including the divided essential genes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_genes_mask = np.isin(all_genes, combined_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_genes_df = merged_df.loc[:, essential_genes_mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_genes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_sums = essential_genes_df.sum()\n",
    "zero_sum_genes = gene_sums[gene_sums == 0].index.tolist()\n",
    "print(f\"Genes that are not present (overall 0 in all samples): {zero_sum_genes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe of just absent essential genes (including the ones that are split up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absent_essential_genes_df = pd.DataFrame()\n",
    "\n",
    "for prefix in absent_genes:\n",
    "    cols_to_merge = essential_genes_df.filter(regex=f'^{prefix}')\n",
    "    absent_essential_genes_df[prefix] = (cols_to_merge.sum(axis=1) > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absent_essential_genes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datafarme of the genes that are divided into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate = essential_genes_df.drop(columns=divided_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the absent essential genes that are present in the dataframe to the overall dataframe of the genes presemt in the datatframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sums = absent_essential_genes_df.sum(axis=0)\n",
    "columns_to_add = absent_essential_genes_df.columns[row_sums != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absent_essential_genes_df[columns_to_add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absent_essential_genes_df[columns_to_add].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding these selected columns to the original DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in absent_essential_genes_df[columns_to_add].columns:\n",
    "    intermediate[col] = absent_essential_genes_df[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intermediate dataframe to plot the frequency of the present in the dataframe genes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/Users/anastasiiashcherbakova/git_projects/masters_project/data/essential_gene_in_ds.npy', intermediate.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EG_distribution = intermediate.sum(axis=1)\n",
    "mean = np.mean(EG_distribution)\n",
    "median = np.median(EG_distribution)\n",
    "min_value = np.min(EG_distribution)\n",
    "max_value = np.max(EG_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.hist(EG_distribution, color='darkorchid', bins=20)\n",
    "plt.xlabel('Essential gene number')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axvline(mean, color='r', linestyle='dashed', linewidth=2, label=f'Mean: {mean:.2f}')\n",
    "plt.axvline(median, color='b', linestyle='dashed', linewidth=2, label=f'Median: {median:.2f}')\n",
    "dummy_min = plt.Line2D([], [], color='black',  linewidth=2, label=f'Min: {min_value:.2f}')\n",
    "dummy_max = plt.Line2D([], [], color='black', linewidth=2, label=f'Max: {max_value:.2f}')\n",
    "\n",
    "handles = [plt.Line2D([], [], color='r', linestyle='dashed', linewidth=2, label=f'Mean: {mean:.2f}'),\n",
    "        plt.Line2D([], [], color='b', linestyle='dashed', linewidth=2, label=f'Median: {median:.2f}'),\n",
    "        dummy_min, dummy_max]\n",
    "plt.legend(handles=handles)\n",
    "plt.savefig(\"/Users/anastasiiashcherbakova/git_projects/masters_project/figures/EG_number.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EG_distribution = intermediate.sum(axis=1) / intermediate.sum(axis=1).max()\n",
    "mean = np.mean(EG_distribution)\n",
    "median = np.median(EG_distribution)\n",
    "min_value = np.min(EG_distribution)\n",
    "max_value = np.max(EG_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.hist(EG_distribution, color='darkorchid', bins=20)\n",
    "plt.xlabel('Essential gene proportion in the dataset')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axvline(mean, color='r', linestyle='dashed', linewidth=2, label=f'Mean: {mean:.2f}')\n",
    "plt.axvline(median, color='b', linestyle='dashed', linewidth=2, label=f'Median: {median:.2f}')\n",
    "dummy_min = plt.Line2D([], [], color='black',  linewidth=2, label=f'Min: {min_value:.2f}')\n",
    "dummy_max = plt.Line2D([], [], color='black', linewidth=2, label=f'Max: {max_value:.2f}')\n",
    "\n",
    "handles = [plt.Line2D([], [], color='r', linestyle='dashed', linewidth=2, label=f'Mean: {mean:.2f}'),\n",
    "        plt.Line2D([], [], color='b', linestyle='dashed', linewidth=2, label=f'Median: {median:.2f}'),\n",
    "        dummy_min, dummy_max]\n",
    "plt.legend(handles=handles)\n",
    "plt.savefig(\"/Users/anastasiiashcherbakova/git_projects/masters_project/figures/EG_number_proportion.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatset_EG = list(intermediate.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_prefix(gene):\n",
    "    match = re.match(r\"([a-zA-Z0-9]+)\", gene)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return gene\n",
    "\n",
    "# Group gene positions by their prefix\n",
    "groups_of_gene_positions = defaultdict(list)\n",
    "for idx, gene in enumerate(all_genes):\n",
    "    prefix = extract_prefix(gene)\n",
    "    groups_of_gene_positions[prefix].append(idx)\n",
    "\n",
    "# Convert defaultdict to a regular dict\n",
    "groups_of_gene_positions = dict(groups_of_gene_positions)\n",
    "\n",
    "# Print the dictionary to verify\n",
    "for prefix, positions in groups_of_gene_positions.items():\n",
    "    print(f\"{prefix}: {positions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precompute essential gene positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_gene_positions = {}\n",
    "for gene in essential_genes_array:\n",
    "    if gene in groups_of_gene_positions.keys():\n",
    "        essential_gene_positions[gene] = groups_of_gene_positions[gene]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_gene_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the abundance of essential genes in the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_gene_abundance = pd.Series(0, index=essential_genes_array)\n",
    "\n",
    "column_names = merged_df.columns\n",
    "\n",
    "for gene, positions in essential_gene_positions.items():\n",
    "    if len(positions) == 1:\n",
    "        pos = positions[0]\n",
    "        column_name = column_names[pos]\n",
    "        essential_gene_abundance[gene] = merged_df[column_name].sum()\n",
    "    else:\n",
    "        column_subset = [column_names[pos] for pos in positions]\n",
    "        essential_gene_abundance[gene] = merged_df[column_subset].sum(axis=1).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_sums = intermediate.sum()\n",
    "mean = np.mean(gene_sums)\n",
    "median = np.median(gene_sums)\n",
    "min_value = np.min(gene_sums)\n",
    "max_value = np.max(gene_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.hist(gene_sums, color='violet')\n",
    "plt.xlabel('Essential gene Abundance')\n",
    "plt.ylabel('Frequence')\n",
    "plt.axvline(mean, color='r', linestyle='dashed', linewidth=2, label=f'Mean: {mean:.2f}')\n",
    "plt.axvline(median, color='b', linestyle='dashed', linewidth=2, label=f'Median: {median:.2f}')\n",
    "dummy_min = plt.Line2D([], [], color='black',  linewidth=2, label=f'Min: {min_value:.2f}')\n",
    "dummy_max = plt.Line2D([], [], color='black', linewidth=2, label=f'Max: {max_value:.2f}')\n",
    "\n",
    "handles = [plt.Line2D([], [], color='r', linestyle='dashed', linewidth=2, label=f'Mean: {mean:.2f}'),\n",
    "        plt.Line2D([], [], color='b', linestyle='dashed', linewidth=2, label=f'Median: {median:.2f}'),\n",
    "        dummy_min, dummy_max]\n",
    "plt.legend(handles=handles)\n",
    "plt.savefig(\"/Users/anastasiiashcherbakova/git_projects/masters_project/figures/essential_genes_frequency.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Minimal gene abundance: {gene_sums.min()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Training of full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1) Full dataset (base model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model \n",
    "input_dim = 55039\n",
    "hidden_dim = 1024\n",
    "latent_dim = 32\n",
    "path_to_model = '/Users/anastasiiashcherbakova/Desktop/2_bigdataset/2_bigdataset/8_final_dataset_new_params/saved_KL_annealing_VAE_BD_100.pt'\n",
    "\n",
    "model, binary_generated_samples = load_model(input_dim, hidden_dim, latent_dim, path_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_name = \"/Users/anastasiiashcherbakova/git_projects/masters_project/figures/sampling_10000_genome_size_distribution_8_final_dataset_new_params.pdf\"\n",
    "plot_color = \"dodgerblue\"\n",
    "\n",
    "plot_samples_distribution(binary_generated_samples, figure_name, plot_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = get_latent_variables(model, test_loader, device)\n",
    "pca = PCA(n_components=2)\n",
    "data_pca = pca.fit_transform(latents)\n",
    "df_pca = pd.DataFrame(data_pca, columns=['PC1', 'PC2'])\n",
    "df_pca['phylogroup'] = test_phylogroups\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.scatterplot(x='PC1', y='PC2', hue = df_pca['phylogroup'], data=df_pca)\n",
    "plt.savefig(\"/Users/anastasiiashcherbakova/git_projects/masters_project/figures/pca_latent_space_visualisation_8_final_dataset_new_params.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_genes_count_per_sample = count_essential_genes(binary_generated_samples, essential_gene_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_color = \"violet\"\n",
    "figure_name =\"/Users/anastasiiashcherbakova/git_projects/masters_project/figures/essential_genes_8_final_dataset_new_params.pdf\"\n",
    "\n",
    "plot_essential_genes_distribution(essential_genes_count_per_sample, figure_name, plot_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1) Full dataset (enhanced model with fropout layers in decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model \n",
    "input_dim = 55039\n",
    "hidden_dim = 1024\n",
    "latent_dim = 32\n",
    "path_to_model = \"/Users/anastasiiashcherbakova/Desktop/2_bigdataset/2_bigdataset/9_final_dataset_enhanced/saved_KL_annealing_VAE_BD_100.pt\"\n",
    "\n",
    "model, binary_generated_samples = load_model_enhanced(input_dim, hidden_dim, latent_dim, path_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_name = \"/Users/anastasiiashcherbakova/git_projects/masters_project/figures/sampling_10000_genome_size_distribution_9_final_dataset_enhanced.pdf\"\n",
    "plot_color = \"dodgerblue\"\n",
    "\n",
    "plot_samples_distribution(binary_generated_samples, figure_name, plot_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = get_latent_variables(model, test_loader, device)\n",
    "pca = PCA(n_components=2)\n",
    "data_pca = pca.fit_transform(latents)\n",
    "df_pca = pd.DataFrame(data_pca, columns=['PC1', 'PC2'])\n",
    "df_pca['phylogroup'] = test_phylogroups\n",
    "\n",
    "# Plot the PCA results\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.scatterplot(x='PC1', y='PC2', hue = df_pca['phylogroup'], data=df_pca)\n",
    "plt.savefig(\"/Users/anastasiiashcherbakova/git_projects/masters_project/figures/pca_latent_space_visualisation_9_final_dataset_enhanced.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_genes_count_per_sample = count_essential_genes(binary_generated_samples, essential_gene_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_name = \"/Users/anastasiiashcherbakova/git_projects/masters_project/figures/essential_genes_9_final_dataset_enhanced.pdf\"\n",
    "plot_color = \"violet\"\n",
    "\n",
    "plot_essential_genes_distribution(essential_genes_count_per_sample, figure_name, plot_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Exploring ways to minimise genome size (new loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1) New loss (VAE v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just ran a test model with random initial parameters to see how it woudl perform with a new loss (gene abundance) included. L1 regularisation applied to the fetures in the model. one note: the new loss gama and beta params: \n",
    "beta_start = 0.1\n",
    "beta_end = 1.0\n",
    "gamma_start = 1.0\n",
    "gamma_end = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "input_dim = 55039\n",
    "hidden_dim = 512\n",
    "latent_dim = 32\n",
    "path_to_model = \"/Users/anastasiiashcherbakova/git_projects/masters_project/genomes/models/saved_8_new_loss_model.pt\"\n",
    "\n",
    "model, binary_generated_samples = load_model(input_dim, hidden_dim, latent_dim, path_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_name = \"/Users/anastasiiashcherbakova/git_projects/masters_project/figures/sampling_10000_genome_size_distribution_8_new_loss.pdf\"\n",
    "plot_color = \"dodgerblue\"\n",
    "\n",
    "plot_samples_distribution(binary_generated_samples, figure_name, plot_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = get_latent_variables(model, test_loader, device)\n",
    "pca = PCA(n_components=2)\n",
    "data_pca = pca.fit_transform(latents)\n",
    "df_pca = pd.DataFrame(data_pca, columns=['PC1', 'PC2'])\n",
    "df_pca['phylogroup'] = test_phylogroups\n",
    "\n",
    "# Plot the PCA results\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.scatterplot(x='PC1', y='PC2', hue = df_pca['phylogroup'], data=df_pca)\n",
    "plt.savefig(\"/Users/anastasiiashcherbakova/git_projects/masters_project/figures/pca_latent_space_visualisation_8_new_loss.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_genes_count_per_sample = count_essential_genes(binary_generated_samples, essential_gene_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_name = \"/Users/anastasiiashcherbakova/git_projects/masters_project/figures/essential_genes_8_new_loss.pdf\"\n",
    "plot_color = \"violet\"\n",
    "\n",
    "plot_essential_genes_distribution(essential_genes_count_per_sample, figure_name, plot_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1) New loss (VAE v1 but with a dropout layer in decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model \n",
    "input_dim = 55039\n",
    "hidden_dim = 512\n",
    "latent_dim = 32\n",
    "\n",
    "path_to_model = \"/Users/anastasiiashcherbakova/git_projects/masters_project/genomes/models/saved_8_new_loss_enhanced_model.pt\"\n",
    "\n",
    "model, binary_generated_samples = load_model_enhanced(input_dim, hidden_dim, latent_dim, path_to_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_name = \"/Users/anastasiiashcherbakova/git_projects/masters_project/figures/sampling_10000_genome_size_distribution_8_new_loss_enhanced_model.pdf\"\n",
    "plot_color = \"dodgerblue\"\n",
    "\n",
    "plot_samples_distribution(binary_generated_samples, figure_name, plot_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = get_latent_variables(model, test_loader, device)\n",
    "pca = PCA(n_components=2)\n",
    "data_pca = pca.fit_transform(latents)\n",
    "df_pca = pd.DataFrame(data_pca, columns=['PC1', 'PC2'])\n",
    "df_pca['phylogroup'] = test_phylogroups\n",
    "\n",
    "# Plot the PCA results\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.scatterplot(x='PC1', y='PC2', hue = df_pca['phylogroup'], data=df_pca)\n",
    "plt.savefig(\"/Users/anastasiiashcherbakova/git_projects/masters_project/figures/pca_latent_space_visualisation_8_new_loss_enhanced_model.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_genes_count_per_sample = count_essential_genes(binary_generated_samples, essential_gene_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_name = \"/Users/anastasiiashcherbakova/git_projects/masters_project/figures/essential_genes_8_new_loss_enhanced_model.pdf\"\n",
    "plot_color = \"violet\"\n",
    "\n",
    "plot_essential_genes_distribution(essential_genes_count_per_sample, figure_name, plot_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1) New loss with no linear annealing (VAE v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model \n",
    "input_dim = 55039\n",
    "hidden_dim = 512\n",
    "latent_dim = 32\n",
    "\n",
    "path_to_model = \"/Users/anastasiiashcherbakova/git_projects/masters_project/genomes/models/saved_11_non_linear_annealing_model.pt\"\n",
    "\n",
    "model, binary_generated_samples = load_model(input_dim, hidden_dim, latent_dim, path_to_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_name = \"/Users/anastasiiashcherbakova/git_projects/masters_project/figures/sampling_10000_genome_size_distribution_11_non_linear_annealing.pdf\"\n",
    "plot_color = \"dodgerblue\"\n",
    "\n",
    "plot_samples_distribution(binary_generated_samples, figure_name, plot_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = get_latent_variables(model, test_loader, device)\n",
    "pca = PCA(n_components=2)\n",
    "data_pca = pca.fit_transform(latents)\n",
    "df_pca = pd.DataFrame(data_pca, columns=['PC1', 'PC2'])\n",
    "df_pca['phylogroup'] = test_phylogroups\n",
    "\n",
    "# Plot the PCA results\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.scatterplot(x='PC1', y='PC2', hue = df_pca['phylogroup'], data=df_pca)\n",
    "plt.savefig(\"/Users/anastasiiashcherbakova/git_projects/masters_project/figures/pca_latent_space_visualisation_11_non_linear_annealing.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_genes_count_per_sample = count_essential_genes(binary_generated_samples, essential_gene_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_name = \"/Users/anastasiiashcherbakova/git_projects/masters_project/figures/essential_genes_11_non_linear_annealing.pdf\"\n",
    "plot_color = \"violet\"\n",
    "\n",
    "plot_essential_genes_distribution(essential_genes_count_per_sample, figure_name, plot_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1) New loss with genome size (VAE v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model \n",
    "input_dim = 55039\n",
    "hidden_dim = 512\n",
    "latent_dim = 32\n",
    "\n",
    "path_to_model = \"/Users/anastasiiashcherbakova/git_projects/masters_project/genomes/models/saved_13_add_genome_size_model.pt\"\n",
    "\n",
    "model, binary_generated_samples = load_model(input_dim, hidden_dim, latent_dim, path_to_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_name = \"/Users/anastasiiashcherbakova/git_projects/masters_project/figures/sampling_10000_genome_size_distribution_13_add_genome_size.pdf\"\n",
    "plot_color = \"dodgerblue\"\n",
    "\n",
    "plot_samples_distribution(binary_generated_samples, figure_name, plot_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = get_latent_variables(model, test_loader, device)\n",
    "pca = PCA(n_components=2)\n",
    "data_pca = pca.fit_transform(latents)\n",
    "df_pca = pd.DataFrame(data_pca, columns=['PC1', 'PC2'])\n",
    "df_pca['phylogroup'] = test_phylogroups\n",
    "\n",
    "# Plot the PCA results\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.scatterplot(x='PC1', y='PC2', hue = df_pca['phylogroup'], data=df_pca)\n",
    "plt.savefig(\"/Users/anastasiiashcherbakova/git_projects/masters_project/figures/pca_latent_space_visualisation_13_add_genome_size_model.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_genes_count_per_sample = count_essential_genes(binary_generated_samples, essential_gene_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_name = \"/Users/anastasiiashcherbakova/git_projects/masters_project/figures/essential_genes_13_add_genome_size.pdf\"\n",
    "plot_color = \"violet\"\n",
    "\n",
    "plot_essential_genes_distribution(essential_genes_count_per_sample, figure_name, plot_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1) New loss with non lenaer annelaing and genome size (VAE v4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model \n",
    "input_dim = 55039\n",
    "hidden_dim = 512\n",
    "latent_dim = 32\n",
    "\n",
    "path_to_model = \"/Users/anastasiiashcherbakova/git_projects/masters_project/genomes/models/saved_15_genome_size_and_cyclic_annealing_SCALED_model.pt\"\n",
    "\n",
    "model, binary_generated_samples = load_model(input_dim, hidden_dim, latent_dim, path_to_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_name = \"/Users/anastasiiashcherbakova/git_projects/masters_project/figures/sampling_10000_genome_size_distribution_15_genome_size_and_cyclic_annealing_SCALED.pdf\"\n",
    "plot_color = \"dodgerblue\"\n",
    "\n",
    "plot_samples_distribution(binary_generated_samples, figure_name, plot_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = get_latent_variables(model, test_loader, device)\n",
    "pca = PCA(n_components=2)\n",
    "data_pca = pca.fit_transform(latents)\n",
    "df_pca = pd.DataFrame(data_pca, columns=['PC1', 'PC2'])\n",
    "df_pca['phylogroup'] = test_phylogroups\n",
    "\n",
    "# Plot the PCA results\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.scatterplot(x='PC1', y='PC2', hue = df_pca['phylogroup'], data=df_pca)\n",
    "plt.savefig(\"/Users/anastasiiashcherbakova/git_projects/masters_project/figures/pca_latent_space_visualisation_15_genome_size_and_cyclic_annealing_SCALED.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_genes_count_per_sample = count_essential_genes(binary_generated_samples, essential_gene_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_name = \"/Users/anastasiiashcherbakova/git_projects/masters_project/figures/essential_genes_15_genome_size_and_cyclic_annealing_SCALED.pdf\"\n",
    "plot_color = \"violet\"\n",
    "\n",
    "plot_essential_genes_distribution(essential_genes_count_per_sample, figure_name, plot_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(binary_generated_samples.sum(axis=1), essential_genes_count_per_sample, color='violet')\n",
    "\n",
    "coefficients = np.polyfit(binary_generated_samples.sum(axis=1), essential_genes_count_per_sample, 1)\n",
    "trendline = np.poly1d(coefficients)\n",
    "\n",
    "plt.plot(binary_generated_samples.sum(axis=1), trendline(binary_generated_samples.sum(axis=1)), color='black', linewidth=2)\n",
    "\n",
    "plt.xlabel('Essential genes number') \n",
    "plt.ylabel('Number of essential gene')\n",
    "\n",
    "plt.savefig(\"/Users/anastasiiashcherbakova/git_projects/masters_project/figures/GS_EG_15_genome_size_and_cyclic_annealing_SCALED.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(num_samples, latent_dim)  # Sample from the standard normal distribution because the latent space follows normal distribution \n",
    "    generated_samples = model.decode(z).cpu().numpy() \n",
    "\n",
    "threshold = 0.5\n",
    "binary_generated_samples = (generated_samples > threshold).astype(float)\n",
    "\n",
    "print(\"Generated samples (binary):\\n\", binary_generated_samples)\n",
    "print(\"\\n\")\n",
    "print(\"Generated samples (sigmoid function output):\\n\", generated_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ones = np.sum(binary_generated_samples, axis=1)\n",
    "min_ones_index = np.argmin(total_ones)\n",
    "\n",
    "latent_distances = np.linalg.norm(generated_samples - generated_samples[min_ones_index], axis=1)\n",
    "\n",
    "closest_latent_index = np.argmin(latent_distances)\n",
    "\n",
    "print(f\"Closest latent vector (z): {z[closest_latent_index]}\")\n",
    "print(f\"Generated sample from closest latent vector:\\n {generated_samples[closest_latent_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(binary_generated_samples[min_ones_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling additional samples from the minimal genomes region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_of_interest = z[closest_latent_index] \n",
    "z_of_interest_tensor = torch.tensor(z_of_interest).unsqueeze(0)  \n",
    "\n",
    "noise_std = 0.1\n",
    "\n",
    "num_additional_samples = 10000  \n",
    "with torch.no_grad():\n",
    "    noise = torch.randn(num_additional_samples, latent_dim) * noise_std\n",
    "    z_samples = z_of_interest_tensor + noise\n",
    "    additional_generated_samples = model.decode(z_samples).cpu().numpy()\n",
    "\n",
    "\n",
    "print(\"Additional generated samples:\")\n",
    "print(additional_generated_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "additional_generated_samples = (additional_generated_samples > threshold).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_name = \"/Users/anastasiiashcherbakova/git_projects/masters_project/figures/additional_sampling_10000_genome_size_distribution_15_genome_size_and_cyclic_annealing_SCALED.pdf\"\n",
    "plot_color = \"dodgerblue\"\n",
    "\n",
    "plot_samples_distribution(additional_generated_samples, figure_name, plot_color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/Users/anastasiiashcherbakova/git_projects/masters_project/data/additional_generated_samples.npy', additional_generated_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_genes_count_per_sample = count_essential_genes(additional_generated_samples, essential_gene_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_name = \"/Users/anastasiiashcherbakova/git_projects/masters_project/figures/additioinal_essential_genes_15_genome_size_and_cyclic_annealing_SCALED.pdf\"\n",
    "plot_color = \"violet\"\n",
    "\n",
    "plot_essential_genes_distribution(essential_genes_count_per_sample, figure_name, plot_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(additional_generated_samples.sum(axis=1), essential_genes_count_per_sample, color='violet')\n",
    "\n",
    "coefficients = np.polyfit(additional_generated_samples.sum(axis=1), essential_genes_count_per_sample, 1)\n",
    "trendline = np.poly1d(coefficients)\n",
    "\n",
    "plt.plot(additional_generated_samples.sum(axis=1), trendline(additional_generated_samples.sum(axis=1)), color='black', linewidth=2)\n",
    "\n",
    "plt.xlabel('Essential genes number') \n",
    "plt.ylabel('Number of essential gene')\n",
    "\n",
    "plt.savefig(\"/Users/anastasiiashcherbakova/git_projects/masters_project/figures/additional_GS_EG_15_genome_size_and_cyclic_annealing_SCALED.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Creating lists of lists with all genes in the sampled genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_prefix(gene):\n",
    "    match = re.match(r\"([a-zA-Z0-9]+)\", gene)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return gene\n",
    "\n",
    "# Step 1: Get the top 100 essential gene counts\n",
    "top_100_values = np.sort(essential_genes_count_per_sample)[-100:][::-1]\n",
    "\n",
    "# Step 2: Find the sequence indices in the array\n",
    "sequence_indices = []\n",
    "for value in top_100_values:\n",
    "    indices = np.where(essential_genes_count_per_sample == value)[0]\n",
    "    sequence_indices.extend(indices)\n",
    "\n",
    "# Ensure we only get the first 100 unique indices in case of duplicates\n",
    "sequence_indices = sequence_indices[:100]\n",
    "\n",
    "# Step 3: Get the samples from additional_generated_samples\n",
    "samples = additional_generated_samples[sequence_indices]\n",
    "\n",
    "# Step 4: Find what genes they have present\n",
    "present_genes_lists = []\n",
    "for sample in samples:\n",
    "    present_genes = all_genes[:-1][sample == 1]\n",
    "    present_genes_lists.append(present_genes)\n",
    "\n",
    "# Step 5: Clean up the gene names and add essential genes\n",
    "cleaned_genes_lists = []\n",
    "for genes in present_genes_lists:\n",
    "    cleaned_gene_names = [extract_prefix(name) for name in genes]\n",
    "    cleaned_gene_names.extend(datatset_EG) \n",
    "    cleaned_genes_lists.append(cleaned_gene_names)\n",
    "\n",
    "np.save('/Users/anastasiiashcherbakova/git_projects/masters_project/data/cleaned_genes_lists.npy', np.array(cleaned_genes_lists, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (EXTRA) 7) Comparing the two different essential genes arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step was done early on, however, we also compared the number of essential genes in on this website (https://shigen.nig.ac.jp/ecoli/pec/) with the essnetial genes in the dataset and we figures out we shoudl use Goodall et. al. essential genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/anastasiiashcherbakova/git_projects/masters_project/data/essential_genes_website.txt'\n",
    "\n",
    "df = pd.read_csv(file_path, delimiter='\\t')  \n",
    "\n",
    "df.to_csv('/Users/anastasiiashcherbakova/git_projects/masters_project/data/essential_genes_website.csv', index=False)\n",
    "\n",
    "essential_genes_website = pd.read_csv('/Users/anastasiiashcherbakova/git_projects/masters_project/data/essential_genes_website.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_genes_website_array = np.array(essential_genes_website['Gene Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_genes_mask = np.isin(all_genes, essential_genes_website_array)\n",
    "essential_genes_df = merged_df.loc[:, essential_genes_mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_genes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_genes_present_array = np.array(essential_genes_df.columns)\n",
    "print(f\"Essential genes present in the dataset: {len(essential_genes_present_array)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_missing = list(set(essential_genes_website_array) - set(essential_genes_present_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Missing genes: {len(genes_missing)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_columns = []\n",
    "\n",
    "for gene in genes_missing:\n",
    "    pattern = re.compile(f\"{gene}\")\n",
    "    matches = [col for col in merged_df.columns if pattern.match(col) and col not in present_genes]\n",
    "    matched_columns.extend(matches)\n",
    "\n",
    "\n",
    "divided_genes = np.array(matched_columns)\n",
    "print(divided_genes)\n",
    "print(len(divided_genes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_genes = ['ssb', 'dnaC', 'metG', 'fabG', 'lptB', 'msbA', 'fbaA', 'lolD', 'topA', 'lptG'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the values that are only in essential genes form the website\n",
    "unique_in_array1 = np.setdiff1d(essential_genes_website_array, essential_genes_array)\n",
    "\n",
    "# Find the values that are only in essential genes form the paper\n",
    "unique_in_array2 = np.setdiff1d(essential_genes_array, essential_genes_website_array)\n",
    "\n",
    "print(\"Values only in website array:\", unique_in_array1)\n",
    "print(\"Values only in paper array:\", unique_in_array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
